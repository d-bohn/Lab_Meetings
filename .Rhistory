stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
finalmap
map <- get_map(location=c(lon=-77.8599,lat=40.7933), zoom=5, maptype="hybrid")
finalmap <- ggmap(map, base_layer = ggplot(aes(x=longitude, y=latitude), data = df))
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
finalmap
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
finalmap
map <- get_map(location=c(lon=-77.8599,lat=40.7933), zoom=8, maptype="hybrid")
finalmap <- ggmap(map, base_layer = ggplot(aes(x=longitude, y=latitude), data = df))
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
finalmap
#Coordinates of somewhere-in-Los-Angeles
location <- "Pennsylvania"
longitude <- c("-77.8599")
latitude <- c("40.7933")
radius <- "200mi"
latlong <- paste(latitude,longitude,radius,sep=",")
latlong <- rep(ll, length(search_terms))
search_terms <- as.data.frame(cbind(latlong, search_terms))
search_terms$search_terms <- as.character(search_terms$search_terms)
search_terms$latlong <- as.character(search_terms$latlong)
search_terms$location <- location
tweets <- data.frame()
for (i in 1:nrow(search_terms)){
print(paste("Looking for",search_terms$search_terms[i], "in", search_terms[i,]$location))
tw = searchTwitter(search_terms[i,]$search_terms,n=round(2000/nrow(search_terms)), geocode=search_terms[i,]$latlong, lang="en")
if (length(tw) == 0){
print(paste("No tweets found for", search_terms$search_terms[i], "in", location))
} else {
tweets=rbind(twListToDF(tw), tweets)
}
}
df <- count(tweets, c("longitude","latitude"))
df <- na.omit(df)
df$longitude <- as.numeric(df$longitude)
df$latitude <- as.numeric(df$latitude)
map <- get_map(location=c(lon=-77.8599,lat=40.7933), zoom=8, maptype="hybrid")
View(df)
finalmap <- ggmap(map, base_layer = ggplot(aes(x=longitude, y=latitude), data = df))
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
finalmap
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
search_terms <- c("trump", "#trump", "Trump")
location <- "Pennsylvania"
longitude <- c("-77.8599")
latitude <- c("40.7933")
radius <- "500mi"
latlong <- paste(latitude,longitude,radius,sep=",")
latlong <- rep(ll, length(search_terms))
search_terms <- as.data.frame(cbind(latlong, search_terms))
search_terms$search_terms <- as.character(search_terms$search_terms)
search_terms$latlong <- as.character(search_terms$latlong)
search_terms$location <- location
tweets <- data.frame()
for (i in 1:nrow(search_terms)){
print(paste("Looking for",search_terms$search_terms[i], "in", search_terms[i,]$location))
tw = searchTwitter(search_terms[i,]$search_terms,n=round(2000/nrow(search_terms)), geocode=search_terms[i,]$latlong, lang="en")
if (length(tw) == 0){
print(paste("No tweets found for", search_terms$search_terms[i], "in", location))
} else {
tweets=rbind(twListToDF(tw), tweets)
}
}
df <- count(tweets, c("longitude","latitude"))
df <- na.omit(df)
df$longitude <- as.numeric(df$longitude)
df$latitude <- as.numeric(df$latitude)
map <- get_map(location=c(lon=-77.8599,lat=40.7933), zoom=8, maptype="hybrid")
finalmap <- ggmap(map, base_layer = ggplot(aes(x=longitude, y=latitude), data = df))
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
View(df)
df <- as.data.frame(count(tweets, c("longitude","latitude")))
df <- na.omit(df)
df$longitude <- as.numeric(df$longitude)
df$latitude <- as.numeric(df$latitude)
df$freq <- as.numeric(df$freq)
finalmap <- ggmap(map, base_layer = ggplot(aes(x=longitude, y=latitude), data = df))
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
map <- get_map(location=c(lon=-77.8599,lat=40.7933), zoom=5, maptype="hybrid")
finalmap <- ggmap(map, base_layer = ggplot(aes(x=longitude, y=latitude), data = df))
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
radius <- "200mi"
for (i in 1:nrow(search_terms)){
print(paste("Looking for",search_terms$search_terms[i], "in", search_terms[i,]$location))
tw = searchTwitter(search_terms[i,]$search_terms,n=round(2000/nrow(search_terms)), geocode=search_terms[i,]$latlong, lang="en")
if (length(tw) == 0){
print(paste("No tweets found for", search_terms$search_terms[i], "in", location))
} else {
tweets=rbind(twListToDF(tw), tweets)
}
}
radius <- "100mi"
for (i in 1:nrow(search_terms)){
print(paste("Looking for",search_terms$search_terms[i], "in", search_terms[i,]$location))
tw = searchTwitter(search_terms[i,]$search_terms,n=round(2000/nrow(search_terms)), geocode=search_terms[i,]$latlong, lang="en")
if (length(tw) == 0){
print(paste("No tweets found for", search_terms$search_terms[i], "in", location))
} else {
tweets=rbind(twListToDF(tw), tweets)
}
}
df <- as.data.frame(count(tweets, c("longitude","latitude")))
df <- na.omit(df)
df$longitude <- as.numeric(df$longitude)
df$latitude <- as.numeric(df$latitude)
df$freq <- as.numeric(df$freq)
#getmap
map <- get_map(location=c(lon=-77.8599,lat=40.7933), zoom=5, maptype="hybrid")
finalmap <- ggmap(map, base_layer = ggplot(aes(x=longitude, y=latitude), data = df))
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
geom_point(col="grey80", size = (df$freq)/10)
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
)
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
radius <- "300mi"
for (i in 1:nrow(search_terms)){
print(paste("Looking for",search_terms$search_terms[i], "in", search_terms[i,]$location))
tw = searchTwitter(search_terms[i,]$search_terms,n=round(2000/nrow(search_terms)), geocode=search_terms[i,]$latlong, lang="en")
if (length(tw) == 0){
print(paste("No tweets found for", search_terms$search_terms[i], "in", location))
} else {
tweets=rbind(twListToDF(tw), tweets)
}
}
df <- as.data.frame(count(tweets, c("longitude","latitude")))
df <- na.omit(df)
df$longitude <- as.numeric(df$longitude)
df$latitude <- as.numeric(df$latitude)
df$freq <- as.numeric(df$freq)
map <- get_map(location=c(lon=-77.8599,lat=40.7933), zoom=5, maptype="hybrid")
finalmap <- ggmap(map, base_layer = ggplot(aes(x=longitude, y=latitude), data = df))
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
map <- get_map(location=c(lon=-77.8599,lat=40.7933), zoom=5, maptype="hybrid")
finalmap <- ggmap(map, base_layer = ggplot(aes(x=longitude, y=latitude), data = df))
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
map <- get_map(location=c(lon=-77.8599,lat=40.7933), zoom=6, maptype="hybrid")
finalmap <- ggmap(map, base_layer = ggplot(aes(x=longitude, y=latitude), data = df))
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
data = df) +
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
geom_point(col="grey80", size = (df$freq)/10)
map <- get_map(location=c(lon=-77.8599,lat=40.7933), zoom=4, maptype="hybrid")
finalmap <- ggmap(map, base_layer = ggplot(aes(x=longitude, y=latitude), data = df))
finalmap +
stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level.., size=freq),
bins = 9, geom = "polygon",alpha=0.2,
scale_fill_gradient(trans = "sqrt", low = "grey5", high = "greenyellow") +
data = df) +
geom_point(col="grey80", size = (df$freq)/10)
library(sentiment);library(ggplot2)
setwd("~/Documents/School Work/Lab_Meetings/03.30.16")
data <- readLines("Palin_Endorsement.txt")
source("scripts/misc_text_functions.R")
data <- ToSentences(data)
df <- data.frame(data)
textdata <- df[df$data, ]
textdata = gsub("[[:punct:]]", "", textdata)
textdata = gsub("[[:punct:]]", "", textdata)
textdata = gsub("[[:digit:]]", "", textdata)
textdata = gsub("http\\w+", "", textdata)
textdata = gsub("[ \t]{2,}", "", textdata)
textdata = gsub("^\\s+|\\s+$", "", textdata)
try.error = function(x)
{
y = NA
try_error = tryCatch(tolower(x), error=function(e) e)
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
textdata = sapply(textdata, try.error)
textdata = textdata[!is.na(textdata)]
names(textdata) = NULL
class_emo = classify_emotion(df, algorithm = "bayes")
emotion = class_emo[,7]
emotion[is.na(emotion)] = "unknown"
class_pol = classify_polarity(df, algorithm="bayes")
polarity = class_pol[,4]
sent_df = data.frame(text=textdata, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion),
decreasing=TRUE))))
sent_df <- sent_df[which(sent_df$emotion != "unknown"),]
#Now that we have processed the comments, we can graph the emotions and polarities.
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="Emotion categories", y="")
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="Polarity categories", y="")
data <- readLines("Romney_plea.txt")
source("misc_text_functions.R")
data <- ToSentences(data)
df <- data.frame(data)
textdata <- df[df$data, ]
textdata = gsub("[[:punct:]]", "", textdata)
textdata = gsub("[[:punct:]]", "", textdata)
textdata = gsub("[[:digit:]]", "", textdata)
textdata = gsub("http\\w+", "", textdata)
textdata = gsub("[ \t]{2,}", "", textdata)
textdata = gsub("^\\s+|\\s+$", "", textdata)
try.error = function(x)
{
y = NA
try_error = tryCatch(tolower(x), error=function(e) e)
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
textdata = sapply(textdata, try.error)
textdata = textdata[!is.na(textdata)]
names(textdata) = NULL
class_emo = classify_emotion(df, algorithm = "bayes")
emotion = class_emo[,7]
emotion[is.na(emotion)] = "unknown"
class_pol = classify_polarity(df, algorithm="bayes")
polarity = class_pol[,4]
sent_df = data.frame(text=textdata, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion),
decreasing=TRUE))))
sent_df <- sent_df[which(sent_df$emotion != "unknown"),]
#Now that we have processed the comments, we can graph the emotions and polarities.
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="Emotion categories", y="")
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="Polarity categories", y="")
View(sent_df)
View(df)
library(twitteR);library(RCurl);library(RJSONIO);library(stringr)
setwd("~/Documents/School Work/Lab_Meetings/03.30.16")
tweets <- searchTwitter("Statistics OR #statistics", n=200, lang="en", since="2014-08-20")
library(twitteR);library(RCurl);library(RJSONIO);library(stringr)
setwd("~/Documents/School Work/Lab_Meetings/03.30.16")
tweets <- searchTwitter("Statistics OR #statistics", n=200, lang="en", since="2014-08-20")
# TwitterR was updated recently, which cause the change in authentication method
# the following works with the latest version of TwitterR
# load necessary packages
if (require(ROAuth) == FALSE) {
install.packages("ROAuth")
library(ROAuth)
}
if (require(twitteR) == FALSE) {
install.packages("twitteR")
library(twitteR)
}
if (require(base64enc) == FALSE) {
install.packages("base64enc")
library(base64enc)
}
if (require(httpuv) == FALSE) {
install.packages("httpuv")
library(httpuv)
}
# consumer key and secret come from twitter
# change the key and secret by the info of your twitter app
consumer_key <- "H2nXd09hWll8U40QD01xs5fmS"
consumer_secret <- "kRWAzRKBHwYwy2poejd7PjihI5uY78LS4sqh920UUsv7ddjM72"
# register function
# input: consumer_key, consumer_secret
register <- function(consumer_key, consumer_secret) {
# register
setup_twitter_oauth(consumer_key, consumer_secret)
### save the authentication for future use
## Setting working folder
# From windows machine in lab computer:
# setwd("D:\\R\\")
# From Mac computer, something like ~/Dropbox/
# setwd(folder_location)
# save the authentication token
# save(my_oauth, file="my_oauth")
}
register(consumer_key, consumer_secret)
tweets <- searchTwitter("Statistics OR #statistics", n=200, lang="en", since="2014-08-20")
library(twitteR);library(RCurl);library(RJSONIO);library(stringr)
setwd("~/Documents/School Work/Lab_Meetings/03.30.16")
tweets <- searchTwitter("Statistics OR #statistics", n=200, lang="en", since="2014-08-20")
# TwitterR was updated recently, which cause the change in authentication method
# the following works with the latest version of TwitterR
# load necessary packages
if (require(ROAuth) == FALSE) {
install.packages("ROAuth")
library(ROAuth)
}
if (require(twitteR) == FALSE) {
install.packages("twitteR")
library(twitteR)
}
if (require(base64enc) == FALSE) {
install.packages("base64enc")
library(base64enc)
}
if (require(httpuv) == FALSE) {
install.packages("httpuv")
library(httpuv)
}
# consumer key and secret come from twitter
# change the key and secret by the info of your twitter app
consumer_key <- "H2nXd09hWll8U40QD01xs5fmS"
consumer_secret <- "kRWAzRKBHwYwy2poejd7PjihI5uY78LS4sqh920UUsv7ddjM72"
# register function
# input: consumer_key, consumer_secret
register <- function(consumer_key, consumer_secret) {
# register
setup_twitter_oauth(consumer_key, consumer_secret)
### save the authentication for future use
## Setting working folder
# From windows machine in lab computer:
# setwd("D:\\R\\")
# From Mac computer, something like ~/Dropbox/
# setwd(folder_location)
# save the authentication token
# save(my_oauth, file="my_oauth")
}
register(consumer_key, consumer_secret)
# TwitterR was updated recently, which cause the change in authentication method
# the following works with the latest version of TwitterR
# load necessary packages
if (require(ROAuth) == FALSE) {
install.packages("ROAuth")
library(ROAuth)
}
if (require(twitteR) == FALSE) {
install.packages("twitteR")
library(twitteR)
}
if (require(base64enc) == FALSE) {
install.packages("base64enc")
library(base64enc)
}
if (require(httpuv) == FALSE) {
install.packages("httpuv")
library(httpuv)
}
# consumer key and secret come from twitter
# change the key and secret by the info of your twitter app
consumer_key <- "H2nXd09hWll8U40QD01xs5fmS"
consumer_secret <- "kRWAzRKBHwYwy2poejd7PjihI5uY78LS4sqh920UUsv7ddjM72"
# register function
# input: consumer_key, consumer_secret
register <- function(consumer_key, consumer_secret) {
# register
setup_twitter_oauth(consumer_key, consumer_secret)
### save the authentication for future use
## Setting working folder
# From windows machine in lab computer:
# setwd("D:\\R\\")
# From Mac computer, something like ~/Dropbox/
# setwd(folder_location)
# save the authentication token
# save(my_oauth, file="my_oauth")
}
register(consumer_key, consumer_secret)
setwd("~/Documents/School Work/Lab_Meetings/03.30.16")
tweets_geolocated <- searchTwitter("PSU OR 'penn state' OR #PSU OR #pennstate", n=500, lang="en",
geocode="40.7982,-77.8599,200mi", since="2014-08-20")
tweets <- twListToDF(tweets_geolocated)
textdata = gsub("[[:punct:]]", "", textdata)
some_txt <- sapply(tweets$text, function(x) gettext(x))
textdata = gsub("[[:punct:]]", "", textdata)
textdata = gsub("[[:digit:]]", "", textdata)
textdata = gsub("http\\w+", "", textdata)
textdata <- sapply(tweets$text, function(x) gettext(x))
textdata = gsub("[[:punct:]]", "", textdata)
textdata = gsub("[[:digit:]]", "", textdata)
textdata = gsub("http\\w+", "", textdata)
textdata = gsub("[ \t]{2,}", "", textdata)
textdata = gsub("^\\s+|\\s+$", "", textdata)
try.error = function(x)
{
y = NA
try_error = tryCatch(tolower(x), error=function(e) e)
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
textdata = sapply(textdata, try.error)
textdata = textdata[!is.na(textdata)]
names(textdata) = NULL
# classify emotion
class_emo = classify_emotion(textdata, algorithm="bayes", prior=1.0)
# get emotion best fit
library(sentiment);library(ggplot2)
class_emo = classify_emotion(textdata, algorithm="bayes", prior=1.0)
# get emotion best fit
emotion = class_emo[,7]
# substitute NA's by "unknown"
emotion[is.na(emotion)] = "unknown"
# classify polarity
class_pol = classify_polarity(textdata, algorithm="bayes")
# get polarity best fit
polarity = class_pol[,4]
# data frame with results
sent_df = data.frame(text=textdata, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
# sort data frame
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
# plot distribution of emotions
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="Emotion Categories for #PSU", y="Count")
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="Polarity Categories for #PSU", y="Count")
View(sent_df)
View(tweets)
install.packages("streamR")
library(streamR)
?filterStream
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
consumerKey <- "H2nXd09hWll8U40QD01xs5fmS"
consumerSecret <- "kRWAzRKBHwYwy2poejd7PjihI5uY78LS4sqh920UUsv7ddjM72"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
library(ROAuth)
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
oauth = my_oauth)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
oauth = my_oauth)
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
